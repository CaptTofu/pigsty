---
######################################################################
# File      :   pigsty-pub.yml
# Desc      :   Pigsty Public Demo Configuration
# Link      :   https://github.com/Vonng/pigsty/wiki/Configuration
# Ctime     :   2020-05-22
# Mtime     :   2022-11-06
# License   :   AGPLv3
# Copyright (C) 2018-2022 Ruohang Feng (rh@vonng.com)
######################################################################

all:
  children:

    meta:                             # special group: meta nodes
      hosts: { 10.10.10.10: { } }
      vars:
        meta_node: true               # mark this group as meta nodes
        ansible_group_priority: 99    # overwrite other group parameters
        patroni_watchdog_mode: off    # do not fencing meta nodes

    infra: # infra cluster for proxy, monitor, alert, etc
      hosts: # 1 for common usage, 3 nodes for production
        10.10.10.10: { infra_seq: 1 } # identity required
        10.10.10.11: { infra_seq: 2 } # assign from 1 ~ n
        10.10.10.12: { infra_seq: 3 } # DO NOT reuse seqs

    etcd: # dcs service for postgres/patroni ha consensus
      hosts:  # 1 node for testing, 3 or 5 for production
        10.10.10.10: { etcd_seq: 1 }  # etcd_seq required
        10.10.10.11: { etcd_seq: 2 }  # assign from 1 ~ n
        10.10.10.12: { etcd_seq: 3 }  # odd number please
      vars: # cluster level parameter override roles/etcd
        etcd_cluster: etcd  # mark etcd cluster name etcd
        etcd_safeguard: false # safeguard against purging
        etcd_clean: true # purge etcd during init process

    pg-meta:
      hosts:
        10.10.10.10: { pg_seq: 1, pg_role: primary }
      vars:
        pg_cluster: pg-meta
        pg_users:
          - { name: dbuser_meta    ,password: DBUser.Meta     ,pgbouncer: true ,roles: [dbrole_admin]    ,comment: pigsty admin user }
          - { name: dbuser_view    ,password: DBUser.Viewer   ,pgbouncer: true ,roles: [dbrole_readonly] ,comment: read-only viewer for meta database }
          - {name: dbuser_grafana  ,password: DBUser.Grafana  ,pgbouncer: true ,roles: [dbrole_admin]    ,comment: admin user for grafana database    }
          - {name: dbuser_bytebase ,password: DBUser.Bytebase ,pgbouncer: true ,roles: [dbrole_admin]    ,comment: admin user for bytebase database   }
          - {name: dbuser_kong     ,password: DBUser.Kong     ,pgbouncer: true ,roles: [dbrole_admin]    ,comment: admin user for kong api gateway    }
          - {name: dbuser_gitea    ,password: DBUser.Gitea    ,pgbouncer: true ,roles: [dbrole_admin]    ,comment: admin user for gitea service       }
          - {name: dbuser_wiki     ,password: DBUser.Wiki     ,pgbouncer: true ,roles: [dbrole_admin]    ,comment: admin user for wiki.js service     }
        pg_databases:
          - { name: meta ,schemas: [pigsty] ,extensions: [{name: timescaledb},{name: postgis,schema: public}] ,baseline: cmdb.sql ,comment: pigsty meta database}
          - { name: grafana  ,owner: dbuser_grafana  ,revokeconn: true ,comment: grafana primary database }
          - { name: bytebase ,owner: dbuser_bytebase ,revokeconn: true ,comment: bytebase primary database }
          - { name: kong     ,owner: dbuser_kong     ,revokeconn: true ,comment: kong the api gateway database }
          - { name: gitea    ,owner: dbuser_gitea    ,revokeconn: true ,comment: gitea meta database }
          - { name: wiki     ,owner: dbuser_wiki     ,revokeconn: true ,comment: wiki meta database }
        pg_libs: 'timescaledb, pg_stat_statements, auto_explain'  # add timescaledb extension
        pg_hba_rules_extra:
          - title: allow application database intranet access
            role: common
            rules:
              - host    kong            dbuser_kong         10.0.0.0/8          md5
              - host    bytebase        dbuser_bytebase     10.0.0.0/8          md5
              - host    grafana         dbuser_grafana      10.0.0.0/8          md5

    # pgsql cluster: pg-test (PostgreSQL 15)
    pg-test:
      hosts:
        10.10.10.11: { pg_seq: 1, pg_role: primary }   # primary instance, leader of cluster
        10.10.10.12: { pg_seq: 2, pg_role: replica }   # replica instance, follower of leader
        10.10.10.13: { pg_seq: 3, pg_role: replica, pg_offline_query: true } # replica with offline access
      vars:
        pg_cluster: pg-test           # define pgsql cluster name
        pg_version: 15                # use postgresql 15 for demonstration
        pg_users:  [{ name: test , password: test , pgbouncer: true , roles: [ dbrole_admin ] }]
        pg_databases: [{name: test}]  # demo database: test
        pg_extensions: ['postgis33_${pg_version}* citus111_${pg_version} pg_repack_${pg_version} wal2json_${pg_version}']
        pg_services_extra:            # extra services in addition to pg_services_default, array of service definition
          # standby service will route {ip|name}:5435 to sync replica's pgbouncer (5435->6432 standby)
          - name: standby             # required, service name, the actual svc name will be prefixed with `pg_cluster`, e.g: pg-meta-standby
            src_ip: "*"               # required, service bind ip address, `*` for all ip, `vip` for cluster `vip_address`
            src_port: 5435            # required, service exposed port (work as kubernetes service node port mode)
            dst_port: pgbouncer       # optional, destination port, postgres|pgbouncer|<port_number>   , pgbouncer(6432) by default
            check_method: http        # optional, health check method: http is the only available method for now
            check_port: patroni       # optional, health check port: patroni|pg_exporter|<port_number> , patroni(8008) by default
            check_url: /sync          # optional, health check url path, /read-only?lag=0 by default
            check_code: 200           # optional, health check expected http code, 200 by default
            selector: "[]"            # required, JMESPath to filter inventory ()
            selector_backup: "[? pg_role == `primary`]"  # primary used as backup server for standby service (will not work because /sync for )
            haproxy:                  # optional, adhoc parameters for haproxy service provider (vip_l4 is another service provider)
              maxconn: 3000           # optional, max allowed front-end connection
              balance: roundrobin     # optional, haproxy load balance algorithm (roundrobin by default, other: leastconn)
              default_server_options: 'inter 3s fastinter 1s downinter 5s rise 3 fall 3 on-marked-down shutdown-sessions slowstart 30s maxconn 3000 maxqueue 128 weight 100'


    # redis sentinel
    redis-meta:
      hosts:
        10.10.10.10:
          redis_node: 1
          redis_instances:  { 6001 : {} ,6002 : {} , 6003 : {} }
      vars:
        redis_cluster: redis-meta
        redis_mode: sentinel
        redis_max_memory: 64MB

    # redis cluster
    redis-test:
      hosts:
        10.10.10.11:
          redis_node: 1
          redis_instances: { 6501 : {} ,6502 : {} ,6503 : {} ,6504 : {} ,6505 : {} ,6506 : {} }
        10.10.10.12:
          redis_node: 2
          redis_instances: { 6501 : {} ,6502 : {} ,6503 : {} ,6504 : {} ,6505 : {} ,6506 : {} }
      vars:
        redis_cluster: redis-test           # name of this redis 'cluster'
        redis_mode: cluster                 # standalone,cluster,sentinel
        redis_max_memory: 32MB              # max memory used by each redis instance
        redis_mem_policy: allkeys-lru       # memory eviction policy

    # redis standalone
    redis-common:
      hosts:
        10.10.10.13:
          redis_node: 1
          redis_instances:
            6501: {}
            6502: { replica_of: '10.10.10.13 6501' }
            6503: { replica_of: '10.10.10.13 6501' }
      vars:
        redis_cluster: redis-common         # name of this redis 'cluster'
        redis_mode: standalone              # standalone,cluster,sentinel
        redis_max_memory: 64MB              # max memory used by each redis instance


  vars:                               # global variables
    version: v2.0.0-a1                # pigsty version string
    meta_ip: 10.10.10.10              # primary meta node ip address
    region: default                   # upstream mirror region: default|china|europe
    nginx_upstream:                   # domain names and upstream servers
      - { name: home         , domain: home.pigsty.cc , endpoint: "${meta_ip}:80"   }
      - { name: grafana      , domain: demo.pigsty.cc , endpoint: "${meta_ip}:3000" }
      - { name: loki         , domain: l.pigsty.cc    , endpoint: "${meta_ip}:3100" }
      - { name: prometheus   , domain: p.pigsty.cc    , endpoint: "${meta_ip}:9090" }
      - { name: alertmanager , domain: a.pigsty.cc    , endpoint: "${meta_ip}:9093" }
      - { name: consul       , domain: c.pigsty.cc    , endpoint: "127.0.0.1:8500"  }
      - { name: postgrest    , domain: api.pigsty.cc  , endpoint: "127.0.0.1:8884"  }
      - { name: pgadmin      , domain: adm.pigsty.cc  , endpoint: "127.0.0.1:8885"  }
      - { name: pgweb        , domain: cli.pigsty.cc  , endpoint: "127.0.0.1:8886"  }
      - { name: bytebase     , domain: ddl.pigsty.cc  , endpoint: "127.0.0.1:8887"  }
      - { name: jupyter      , domain: lab.pigsty.cc  , endpoint: "127.0.0.1:8888"  }
      - { name: gitea        , domain: git.pigsty.cc  , endpoint: "127.0.0.1:8889"  }
      - { name: minio        , domain: sss.pigsty.cc  , endpoint: "127.0.0.1:9000"  }
      - { name: wiki         , domain: wiki.pigsty.cc , endpoint: "127.0.0.1:9002"  }
    nginx_indexes:                    # application nav links on home page
      - { name: PgAdmin4   , url : 'http://adm.pigsty.cc'           , comment: 'PgAdmin4 for PostgreSQL'     }
      - { name: PGWeb      , url : 'http://cli.pigsty.cc'           , comment: 'PGWEB Browser Client'        }
      - { name: ByteBase   , url : 'http://ddl.pigsty.cc'           , comment: 'ByteBase Schema Migrator'    }
      - { name: PostgREST  , url : 'http://api.pigsty.cc'           , comment: 'Kong API Gateway'            }
      - { name: Gitea      , url : 'http://git.pigsty.cc'           , comment: 'Gitea Git Service'           }
      - { name: Minio      , url : 'http://sss.pigsty.cc'           , comment: 'Minio Object Storage'        }
      - { name: Wiki       , url : 'http://wiki.pigsty.cc'          , comment: 'Local Wiki Pedia'            }
      - { name: Explain    , url : '/pev.html'                      , comment: 'postgres explain visualizer' }
      - { name: Package    , url : '/pigsty'                        , comment: 'local yum repo packages'     }
      - { name: Matrix Pkg , url : '/matrix'                        , comment: 'matrixdb repo packages'      }
      - { name: PG Logs    , url : '/logs'                          , comment: 'postgres raw csv logs'       }
      - { name: Schemas    , url : '/schema'                        , comment: 'schemaspy summary report'    }
      - { name: Reports    , url : '/report'                        , comment: 'pgbadger summary report'     }
      - { name: ISD        , url : '${grafana}/d/isd-overview'      , comment: 'noaa isd data visualization' }
      - { name: Covid      , url : '${grafana}/d/covid-overview'    , comment: 'covid data visualization'    }
      - { name: Worktime   , url : '${grafana}/d/worktime-overview' , comment: 'worktime query'              }
      - { name: DBTrend    , url : '${grafana}/d/dbeng-trending'    , comment: 'DB Engine Trending Graph'    }
    node_etc_hosts:                   # extra static dns records in /etc/hosts
      - 10.10.10.10 pg-meta           # vip not available on public cloud
      - 10.10.10.11 pg-test           # sandbox vip for pg-test
      - 10.10.10.10 pg-meta-1
      - 10.10.10.11 pg-test-1
      - 10.10.10.12 pg-test-2
      - 10.10.10.13 pg-test-3
    node_timezone: Asia/Hong_Kong     # default node timezone, empty will not change
    node_ntp_servers:                 # NTP servers in /etc/chrony.conf
      - pool cn.pool.ntp.org iburst
      - pool time.pool.aliyun.com iburst
    docker_registry_mirrors: ["https://registry.cn-hangzhou.aliyuncs.com"]
    pg_pwd_enc: scram-sha-256         # algorithm for encrypting passwords: md5|scram-sha-256
    pg_sslmode: require               # enable sslmode: disable|allow|prefer|require|verify-ca|verify-full

...