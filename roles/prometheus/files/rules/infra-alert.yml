---
#==============================================================#
# File      :   infra-alert.yml
# Ctime     :   2021-06-23
# Mtime     :   2021-06-29
# Desc      :   Infrastructure Alerting Rules
# Path      :   /etc/prometheus/rules/infra-alert.yml
# Copyright (C) 2018-2021 Ruohang Feng
#==============================================================#


################################################################
#                     Alert Rule Format                        #
################################################################
# Level: three alert levels
#   0 : CRIT  System failure needs immediate intervene   call  (e.g down) 1m
#   1 : WARN  Anomalies could lead to failure soon       sms   (e.g high) 1m
#   2 : INFO  Warning events that need attention         mail             5m

# - alert: InfraDown        <------- CamelCase Alert Name
#   expr: infra_up < 1      <------- Expression
#   for: 1m                 <------- Duration Threshold
#        ^------- (omit) : Trigger immediately
#   labels:
#     level: 0              <------- numeric expression of severity 0,1,2
#     severity: CRIT        <------- alert severity: fatal,error,event
#     category: infra       <------- category: infra, node, pgsql, redis, ...
#   annotations:            <------- short & detailed information about context
#     summary: "FATAL InfraDown {{ $labels.type }}@{{ $labels.instance }}"
#     description: |
#       infra_up[instance={{ $labels.instance }}] = {{ $value  | printf "%.2f" }} < 1
################################################################


groups:

  # infra-alert depends on metrics defined in infra.yml

  - name: infra-alert
    rules:

      ################################################################
      #                     Infrastructure Alert                     #
      ################################################################

      #==============================================================#
      #                       Infra Aliveness                        #
      #==============================================================#
      # infra components (prometheus,grafana) down for 1m triggers a P1 alert
      - alert: InfraDown
        expr: infra_up < 1
        for: 1m
        labels: { level: 0, severity: CRIT, category: infra }
        annotations:
          summary: "CRIT InfraDown {{ $labels.type }}@{{ $labels.instance }}"
          description: |
            infra_up[type={{ $labels.type }}, instance={{ $labels.instance }}] = {{ $value  | printf "%.2f" }} < 1
            http://g.pigsty/d/pgsql-alert?viewPanel=32


      #==============================================================#
      #                       Agent Aliveness                        #
      #==============================================================#
      # node & haproxy aliveness are determined directly by exporter aliveness
      # including: node_exporter, pg_exporter, pgbouncer_exporter, haproxy_exporter
      - alert: AgentDown
        expr: agent_up < 1
        for: 1m
        labels: { level: 0, severity: CRIT, category: infra }
        annotations:
          summary: 'CRIT AgentDown {{ $labels.ins }}@{{ $labels.instance }}'
          description: |
            agent_up[ins={{ $labels.ins }}, instance={{ $labels.instance }}] = {{ $value  | printf "%.2f" }} < 1
            http://g.pigsty/d/pgsql-alert?viewPanel=22


      #==============================================================#
      #                         Prometheus                           #
      #==============================================================#
      # TODO

      #==============================================================#
      #                           Grafana                            #
      #==============================================================#
      # TODO

      #==============================================================#
      #                           Consul                             #
      #==============================================================#
      # TODO

      #==============================================================#
      #                            Etcd                              #
      #==============================================================#
      # TODO



      ################################################################
      #                          Node Alert                          #
      ################################################################
      # https://awesome-prometheus-alerts.grep.to/rules

      #==============================================================#
      #                          Node : CPU                          #
      #==============================================================#
      # cpu usage high : 1m avg cpu usage > 70% for 3m
      - alert: NodeCpuHigh
        expr: node:ins:cpu_usage_1m > 0.70
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeCpuHigh {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.2f" }}'
          description: |
            node:ins:cpu_usage[ins={{ $labels.ins }}] = {{ $value  | printf "%.2f" }} > 70%

      # OPTIONAL: one core high
      # OPTIONAL: throttled
      # OPTIONAL: frequency
      # OPTIONAL: steal

      #==============================================================#
      #                       Node : Schedule                        #
      #==============================================================#
      # node load high : 1m avg standard load > 100% for 3m
      - alert: NodeLoadHigh
        expr: node:ins:stdload1 > 1
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeLoadHigh {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.2f" }}'
          description: |
            node:ins:stdload1[ins={{ $labels.ins }}] = {{ $value  | printf "%.2f" }} > 100%


      #==============================================================#
      #                        Node : Memory                         #
      #==============================================================#
      # available memory < 10%
      - alert: NodeOutOfMem
        expr: node:ins:mem_avail < 0.10
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeOutOfMem {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.2f" }}'
          description: |
            node:ins:mem_avail[ins={{ $labels.ins }}] = {{ $value  | printf "%.2f" }} < 10%

      # OPTIONAL: EDAC Errors

      #==============================================================#
      #                        Node : Swap                           #
      #==============================================================#
      # swap usage > 1%
      - alert: NodeMemSwapped
        expr: node:ins:swap_usage > 0.01
        for: 5m
        labels: { level: 2, severity: INFO, category: node }
        annotations:
          summary: 'INFO NodeMemSwapped {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.2f" }}'
          description: |
            node:ins:swap_usage[ins={{ $labels.ins }}] = {{ $value  | printf "%.2f" }} > 1%

      #==============================================================#
      #                     Node : File System                       #
      #==============================================================#

      # filesystem usage > 90%
      - alert: NodeFsSpaceFull
        expr: node:fs:space_usage > 0.90
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeFsSpaceFull {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.2f" }}'
          description: |
            node:fs:space_usage[ins={{ $labels.ins }}] = {{ $value  | printf "%.2f" }} > 90%

      # inode usage > 90%
      - alert: NodeFsFilesFull
        expr: node:fs:inode_usage > 0.90
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeFsFilesFull {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.2f" }}'
          description: |
            node:fs:inode_usage[ins={{ $labels.ins }}] = {{ $value  | printf "%.2f" }} > 90%

      # file descriptor usage > 90%
      - alert: NodeFdFull
        expr: node:ins:fd_usage > 0.90
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeFdFull {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.2f" }}'
          description: |
            node:ins:fd_usage[ins={{ $labels.ins }}] = {{ $value  | printf "%.2f" }} > 90%

      # OPTIONAL: space predict 1d
      # OPTIONAL: filesystem read-only
      # OPTIONAL: fast release on disk space

      #==============================================================#
      #                          Node : Disk                         #
      #==============================================================#
      # read latency > 32ms (typical on pci-e ssd: 100Âµs)
      - alert: NodeDiskSlow
        expr: node:dev:disk_read_rt_1m > 0.032 or node:dev:disk_write_rt_1m > 0.032
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeReadSlow {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.6f" }}'
          description: |
            node:dev:disk_read_rt_1m[ins={{ $labels.ins }}] = {{ $value  | printf "%.6f" }} > 32ms

      # OPTIONAL: raid card failure
      # OPTIONAL: read/write traffic high
      # OPTIONAL: read/write latency high

      #==============================================================#
      #                        Node : Network                        #
      #==============================================================#
      # OPTIONAL: unusual network traffic
      # OPTIONAL: interface saturation high

      #==============================================================#
      #                        Node : Protocol                       #
      #==============================================================#

      # rate(node:ins:tcp_error[1m]) > 1
      - alert: NodeTcpErrHigh
        expr: rate(node:ins:tcp_error[1m]) > 1
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeTcpErrHigh {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.2f" }}'
          description: |
            rate(node:ins:tcp_error{ins={{ $labels.ins }}}[1m]) = {{ $value  | printf "%.2f" }} > 1

      # node:ins:tcp_retrans_ratio1m > 1e-4
      - alert: NodeTcpRetransHigh
        expr: node:ins:tcp_retrans_ratio1m > 1e-2
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'INFO NodeTcpRetransHigh {{ $labels.ins }}@{{ $labels.instance }} {{ $value  | printf "%.6f" }}'
          description: |
            node:ins:tcp_retrans_ratio1m[ins={{ $labels.ins }}] = {{ $value  | printf "%.6f" }} > 1%

      # OPTIONAL: tcp conn high
      # OPTIONAL: udp traffic high
      # OPTIONAL: conn track


      #==============================================================#
      #                          Node : Time                         #
      #==============================================================#
      # node_ntp_sanity < 1
      - alert: NodeNtpSanity
        expr: node_ntp_sanity < 1 or node_timex_sync_status < 1
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeNtpSanity {{ $labels.ins }}@{{ $labels.instance }}'
          description: |
            node_ntp_sanity[ins={{ $labels.ins }}] = {{ $value }} < 1

      # time offset > 50ms
      - alert: NodeClockSkew
        expr: abs(node_timex_offset_seconds) > 0.050
        for: 1m
        labels: { level: 1, severity: WARN, category: node }
        annotations:
          summary: 'WARN NodeClockSkew {{ $labels.ins }}@{{ $labels.instance }}'
          description: |
            abs(node_timex_offset_seconds)[ins={{ $labels.ins }}]) = {{ $value | printf "%.6f" }} > 50ms



...