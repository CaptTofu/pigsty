---
#==============================================================#
# File      :   node.yml
# Ctime     :   2020-04-22
# Mtime     :   2021-05-30
# Desc      :   Record and alert rules for node exporter
# Path      :   /etc/prometheus/rules/node.yml
# Copyright (C) 2018-2021 Ruohang Feng
#==============================================================#

groups:
  ################################################################
  #                          Node Rules                          #
  ################################################################
  - name: node-rules
    rules:

      ################################################################
      #                     Miscellaneous                            #
      ################################################################
      # node_instance holds (nodename,ins,ip) ID maps to (ins,ip,cls)
      - record: node_instance
        expr: sum by (id,ins,cls,ip,nodename) (label_replace(node_uname_info{job="pg"}, "id", "$1", "nodename", "(.+)") OR label_replace(node_uname_info{job="pg"}, "id", "$1", "instance", "(.+)\\:\\d+")  OR  label_replace(node_uname_info{job="pg"}, "id", "$1", "ins", "(.+)"))

      #==============================================================#
      #                         Aliveness                            #
      #==============================================================#
      # TODO: change this to your node exporter port  (9100 by default)
      - record: node_exporter_up
        expr: min by (cls,ins) (up{instance=~".*:9100"})

      # TODO: change this yo your haproxy exporter port (9101 by default)
      - record: haproxy_exporter_up
        expr: min by (cls,ins) (up{instance=~".*:9101"})

      # seconds since node bootstrap
      - record: node:uptime
        expr: time() - min by (cls,ins) (node_boot_time_seconds{})

      #==============================================================#
      #                             CPU                              #
      #==============================================================#
      - record: haproxy:ins:usage
        expr: avg by (cls,ins)(100 - haproxy_process_idle_time_percent) / 100


      #--------------------------------#
      #           CPU Usage            #
      #--------------------------------#

      # cpu mode time ratio
      - record: node:cpu:cpu_idle
        expr: sum by (cls,ins,cpu) (irate(node_cpu_seconds_total{mode="idle"}[1m]))
      - record: node:cpu:cpu_time
        expr: sum by (cls,ins,cpu) (irate(node_cpu_seconds_total{}[1m]))

      # instance cpu usage , cluster cpu usage
      - record: node:cpu:cpu_usage
        expr: 1 - node:cpu:cpu_idle / node:cpu:cpu_time
      - record: node:ins:cpu_usage
        expr: avg by (cls, ins) (node:cpu:cpu_usage)
      - record: node:cls:cpu_usage
        expr: avg by (cls) (node:cpu:cpu_usage)

      # cpu usage rate1m
      - record: node:cpu:cpu_usage_1m
        expr: avg_over_time(node:cpu:cpu_usage[1m])
      - record: node:ins:cpu_usage_1m
        expr: avg_over_time(node:ins:cpu_usage[1m])
      - record: node:cls:cpu_usage_1m
        expr: avg_over_time(node:cls:cpu_usage[1m])

      # cpu usage rate5m
      - record: node:cpu:cpu_usage_5m
        expr: avg_over_time(node:cpu:cpu_usage[5m])
      - record: node:ins:cpu_usage_5m
        expr: avg_over_time(node:ins:cpu_usage[5m])
      - record: node:cls:cpu_usage_5m
        expr: avg_over_time(node:cls:cpu_usage[5m])

      # cpu usage rate15m
      - record: node:cpu:cpu_usage_15m
        expr: avg_over_time(node:cpu:cpu_usage[15m])
      - record: node:ins:cpu_usage_15m
        expr: avg_over_time(node:ins:cpu_usage[15m])
      - record: node:cls:cpu_usage_15m
        expr: avg_over_time(node:cls:cpu_usage[15m])


      #--------------------------------#
      #           CPU Count            #
      #--------------------------------#
      # cpu count
      - record: node:ins:cpu_count
        expr: count by (cls,ins) (node:cpu:cpu_usage)
      - record: node:cls:cpu_count
        expr: count by (cls) (node:cpu:cpu_usage)


      #--------------------------------#
      #         CPU Time-slice         #
      #--------------------------------#
      # cpu schedule time-slices by (cpu,ins,cls)
      - record: node:cpu:sched_timeslices
        expr: sum by (cls,ins,cpu) (rate(node_schedstat_timeslices_total{}[1m]))
      - record: node:ins:sched_timeslices
        expr: sum by (ins) (node:cpu:sched_timeslices)
      - record: node:cls:sched_timeslicesa
        expr: sum by (cls) (node:ins:sched_timeslices)


      #==============================================================#
      #                            Memory                            #
      #==============================================================#
      # application memory usage
      - record: node:ins:mem_app
        expr: max by (cls,ins) (node_memory_MemTotal_bytes - node_memory_MemFree_bytes - node_memory_Buffers_bytes - node_memory_Cached_bytes - node_memory_Slab_bytes - node_memory_PageTables_bytes - node_memory_SwapCached_bytes)

      # free memory
      - record: node:ins:mem_free
        expr: max by (cls,ins) (node_memory_MemFree_bytes + node_memory_Cached_bytes)

      # memory usage by instance (application mem)
      - record: node:ins:mem_usage
        expr: node:ins:mem_app / on(cls,ins) node_memory_MemTotal_bytes

      # memory usage by cluster (application mem)
      - record: node:cls:mem_usage
        expr: sum by (cls) (node:ins:mem_app) / sum by (cls) (node_memory_MemTotal_bytes)

      # swap memory usage by instance
      - record: node:ins:swap_usage
        expr: 1 - min by (cls,ins) (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)


      #==============================================================#
      #                            Disk                              #
      #==============================================================#
      #--------------------------------#
      #           Disk Usage           #
      #--------------------------------#
      - record: node:dev:disk_usage
        expr: 1 - sum by (cls,ins,device)(node_filesystem_avail_bytes) / sum by (cls,ins,device)(node_filesystem_size_bytes)
      - record: node:ins:disk_usage
        expr: 1 - sum by (cls,ins)(node_filesystem_avail_bytes) / sum by (cls,ins)(node_filesystem_size_bytes)

      #--------------------------------#
      #           Disk IOPS            #
      #--------------------------------#
      # disk read iops
      - record: node:dev:disk_read_iops
        expr: sum by (cls,ins,device) (rate(node_disk_reads_completed_total{device=~"[a-zA-Z-_]+"}[1m]))
      - record: node:ins:disk_read_iops
        expr: sum by (cls,ins) (node:dev:disk_read_iops)
      - record: node:cls:disk_read_iops
        expr: sum by (cls) (node:ins:disk_read_iops)

      # disk write iops
      - record: node:dev:disk_write_iops
        expr: sum by (cls,ins,device) (rate(node_disk_writes_completed_total{device=~"[a-zA-Z-_]+"}[1m]))
      - record: node:ins:disk_write_iops
        expr: sum by (cls,ins) (node:dev:disk_write_iops)
      - record: node:cls:disk_write_iops
        expr: sum by (cls) (node:ins:disk_write_iops)

      # disk iops
      - record: node:dev:disk_iops
        expr: node:dev:disk_read_iops + node:dev:disk_write_iops
      - record: node:ins:disk_iops
        expr: node:ins:disk_read_iops + node:ins:disk_write_iops
      - record: node:cls:disk_iops
        expr: node:cls:disk_read_iops + node:cls:disk_write_iops

      #--------------------------------#
      #         Disk Bandwidth         #
      #--------------------------------#
      # read bandwidth (rate1m)
      - record: node:dev:disk_read_rate
        expr: sum by (cls,ins,device) (rate(node_disk_read_bytes_total{device=~"[a-zA-Z-_]+"}[1m]))
      - record: node:ins:disk_read_rate
        expr: sum by (cls,ins) (node:dev:disk_read_rate)
      - record: node:cls:disk_read_rate
        expr: sum by (cls) (node:ins:disk_read_rate)

      # write bandwidth (rate1m)
      - record: node:dev:disk_write_rate
        expr: sum by (cls,ins,device) (rate(node_disk_written_bytes_total{device=~"[a-zA-Z-_]+"}[1m]))
      - record: node:ins:disk_write_rate
        expr: sum by (cls,ins) (node:dev:disk_write_rate)
      - record: node:cls:disk_write_rate
        expr: sum by (cls) (node:ins:disk_write_rate)

      # io bandwidth (rate1m)
      - record: node:dev:disk_io_rate
        expr: node:dev:disk_read_rate + node:dev:disk_write_rate
      - record: node:ins:disk_io_rate
        expr: node:ins:disk_read_rate + node:ins:disk_write_rate
      - record: node:cls:disk_io_rate
        expr: node:cls:disk_read_rate + node:cls:disk_write_rate

      #--------------------------------#
      #           Disk Time            #
      #--------------------------------#
      # read/write total time
      - record: node:dev:disk_read_time
        expr: sum by (cls,ins,device) (rate(node_disk_read_time_seconds_total{device=~"[a-zA-Z-_]+"}[1m]))
      - record: node:dev:disk_write_time
        expr: sum by (cls,ins,device) (rate(node_disk_read_time_seconds_total{device=~"[a-zA-Z-_]+"}[1m]))

      # read/write response time
      - record: node:dev:disk_read_rt
        expr: node:dev:disk_read_time / node:dev:disk_read_iops
      - record: node:dev:disk_write_rt
        expr: node:dev:disk_write_time / node:dev:disk_write_iops
      - record: node:dev:disk_rt
        expr: (node:dev:disk_read_time + node:dev:disk_write_time) / node:dev:iops


      #==============================================================#
      #                            Network                           #
      #==============================================================#
      # transmit bandwidth (out)
      - record: node:dev:network_tx
        expr: sum by (cls,ins,device) (rate(node_network_transmit_bytes_total{}[1m]))
      - record: node:ins:network_tx
        expr: sum by (cls,ins) (node:dev:network_tx{device!~"lo|bond.*"})
      - record: node:cls:network_tx
        expr: sum by (cls) (node:ins:network_tx)

      # receive bandwidth (in)
      - record: node:dev:network_rx
        expr: sum by (cls,ins,device) (rate(node_network_receive_bytes_total{}[1m]))
      - record: node:ins:network_rx
        expr: sum by (cls,ins) (node:dev:network_rx{device!~"lo|bond.*"})
      - record: node:cls:network_rx
        expr: sum by (cls) (node:ins:network_rx)

      # io bandwidth
      - record: node:dev:network_io
        expr: node:dev:network_tx + node:dev:network_rx
      - record: node:ins:network_io
        expr: node:ins:network_tx + node:ins:network_rx
      - record: node:cls:network_io
        expr: node:cls:network_tx + node:cls:network_rx


      #==============================================================#
      #                           Schedule                           #
      #==============================================================#
      # normalized load
      - record: node:ins:stdload1
        expr: node_load1 / on(cls,ins) node:ins:cpu_count
      - record: node:ins:stdload5
        expr: node_load5 / on(cls,ins) node:ins:cpu_count
      - record: node:ins:stdload15
        expr: node_load15 / on(cls,ins) node:ins:cpu_count

      # process fork
      - record: node:ins:forks
        expr: sum by (cls, ins) (rate(node_forks_total[1m]))

      # interrupt rate
      - record: node:ins:interrupt
        expr: sum by (cls,ins) (rate(node_intr_total[1m]))

      # context switch
      - record: node:ins:ctx_switch
        expr: sum by (cls,ins) (rate(node_context_switches_total{}[1m]))



      #==============================================================#
      #                      Node Saturation                         #
      #==============================================================#
      # max value of pg:ins:load or pgbouncer:ins:load
      # pg saturation of instance level 1,5,15
      - record: node:ins:saturation1
        expr: max by (cls,ins)(node:ins:stdload1 or node:ins:cpu_usage_1m)
      - record: node:ins:saturation5
        expr: max by (cls,ins)(node:ins:stdload5 or node:ins:cpu_usage_5m)
      - record: node:ins:saturation15
        expr: max by (cls,ins)(node:ins:stdload15 or node:ins:cpu_usage_15m)

      # pg saturation of cluster level 1,5,15
      - record: node:cls:saturation1
        expr: max by (cls) (node:cls:load1 or node:cls:cpu_usage_1m)
      - record: node:cls:saturation5
        expr: max by (cls) (node:cls:load5 or node:cls:cpu_usage_5m)
      - record: node:cls:saturation15
        expr: max by (cls) (node:cls:load15 or node:cls:cpu_usage_15m)


      #==============================================================#
      #                              VM                              #
      #==============================================================#
      # page fault (mem page missing)
      - record: node:ins:pagefault
        expr: sum by (cls,ins) (rate(node_vmstat_pgfault[1m]))

      # page in (disk to mem)
      - record: node:ins:pagein
        expr: sum by (cls,ins) (rate(node_vmstat_pgpgin[1m]))

      # page out (mem to disk)
      - record: node:ins:pageout
        expr: sum by (cls,ins) (rate(node_vmstat_pgpgout[1m]))

      # page swap in (swap disk to mem)
      - record: node:ins:swapin
        expr: sum by (cls,ins) (rate(node_vmstat_pswpin[1m]))

      # page swap out (swap mem to disk)
      - record: node:ins:swapout
        expr: sum by (cls,ins) (rate(node_vmstat_pswpout[1m]))


      #==============================================================#
      #                              FS                              #
      #==============================================================#
      # filesystem space usage
      - record: node:fs:free_bytes
        expr: max by(cls,ins,mountpoint) (node_filesystem_free_bytes{fstype!~"(n|root|tmp)fs.*"})
      - record: node:fs:avail_bytes
        expr: max by(cls,ins,mountpoint) (node_filesystem_avail_bytes{fstype!~"(n|root|tmp)fs.*"})
      - record: node:fs:size_bytes
        expr: max by(cls,ins,mountpoint) (node_filesystem_size_bytes{fstype!~"(n|root|tmp)fs.*"})
      - record: node:fs:space_usage
        expr: 1 - (node:fs:avail_bytes{} / node:fs:size_bytes{})
      - record: node:fs:free_inode
        expr: max by(cls,ins,mountpoint)  (node_filesystem_files_free{fstype!~"(n|root|tmp)fs.*"})
      - record: node:fs:total_inode
        expr: max by(cls,ins,mountpoint)  (node_filesystem_files{fstype!~"(n|root|tmp)fs.*"})

      # space delta and prediction
      - record: node:fs:space_deriv_1h
        expr: sum by (cls,ins,device,mountpoint)(deriv(node_filesystem_avail_bytes{}[1h]))
      - record: node:fs:space_exhaust
        expr: (sum by (cls,ins,device,mountpoint)(node_filesystem_avail_bytes) / - node:fs:space_deriv_1h) > 0

      # fs inode usage
      - record: node:fs:inode_usage
        expr: 1 - (node:fs:free_inode / node:fs:total_inode)

      # file descriptor usage
      - record: node:ins:fd_usage
        expr: max by (cls,ins) (node_filefd_allocated / node_filefd_maximum)


      #==============================================================#
      #                             TCP                              #
      #==============================================================#
      # tcp segments (rate1m)
      - record: node:ins:tcp_insegs
        expr: sum by (cls,ins) (rate(node_netstat_Tcp_InSegs{}[1m]))

      - record: node:ins:tcp_outsegs
        expr: sum by (cls,ins) (rate(node_netstat_Tcp_OutSegs{}[1m]))

      - record: node:ins:tcp_retranssegs
        expr: sum by (cls,ins) (rate(node_netstat_Tcp_RetransSegs{}[1m]))

      - record: node:ins:tcp_segs
        expr: node:ins:tcp_insegs + node:ins:tcp_outsegs

      # retransmit
      - record: node:ins:tcp_retrans_rate
        expr: node:ins:tcp_retranssegs / node:ins:tcp_outsegs

      # overflow
      - record: node:ins:tcp_overflow_rate
        expr: sum by (cls,ins) (rate(node_netstat_TcpExt_ListenOverflows[1m]))

      # tcp error count
      - record: node:ins:tcp_error
        expr: sum by (cls,ins)(node_netstat_TcpExt_ListenOverflows + node_netstat_TcpExt_ListenDrops + node_netstat_Tcp_InErrs)

      # tcp error rate
      - record: node:ins:tcp_error_rate
        expr: rate(node:ins:tcp_error[1m])

      #==============================================================#
      #                           Netstat                            #
      #==============================================================#
      # tcp open (rate1m)
      - record: node:ins:tcp_passive_opens
        expr: sum by (cls,ins) (rate(node_netstat_Tcp_PassiveOpens[1m]))

      - record: node:ins:tcp_active_opens
        expr: sum by (cls,ins) (rate(node_netstat_Tcp_ActiveOpens[1m]))

      # tcp close
      - record: node:ins:tcp_attempt_fails
        expr: sum by (cls,ins) (rate(node_netstat_Tcp_AttemptFails[1m]))

      - record: node:ins:tcp_estab_resets
        expr: sum by (cls,ins) (rate(node_netstat_Tcp_EstabResets[1m]))

      # tcp drop
      - record: node:ins:tcp_overflow
        expr: sum by (cls,ins) (rate(node_netstat_TcpExt_ListenOverflows[1m]))

      - record: node:ins:tcp_dropped
        expr: sum by (cls,ins) (rate(node_netstat_TcpExt_ListenDrops[1m]))


      #==============================================================#
      #                             NTP                              #
      #==============================================================#
      - record: node:cls:ntp_offset_max
        expr: max by (cls)(node_ntp_offset_seconds)

      - record: node:cls:ntp_offset_min
        expr: min by (cls)(node_ntp_offset_seconds)

      - record: node:cls:ntp_offset_range
        expr: max by (cls)(node_ntp_offset_seconds) - min by (cls)(node_ntp_offset_seconds)







  ################################################################
  #                          Node Alert                          #
  ################################################################
  - name: node-alert
    rules:

      # node exporter down for 1m triggers a P1 alert
      - alert: NODE_EXPORTER_DOWN
        expr: up{instance=~"^.*:(9100)$"} == 0
        for: 1m
        labels:
          severity: P1
        annotations:
          summary: "P1 Node Exporter Down: {{ $labels.ins }} {{ $value }}"
          description: |
            up[instance={{ $labels.instance }}] = {{ $value }} == 0
            https://dba.p1staff.com/d/node?var-ip={{ $labels.instance }}&from=now-5m&to=now&refresh=10s



      #==============================================================#
      #                          CPU & Load                          #
      #==============================================================#
      # node avg CPU usage > 90% for 1m
      - alert: NODE_CPU_HIGH
        expr: node:ins:cpu_usage > 0.90
        for: 1m
        labels:
          severity: P1
        annotations:
          summary: "P1 Node CPU High: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:ins:cpu_usage[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 90%
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=28&fullscreen&var-ip={{ $labels.ip }}

      # node load5 > 100%
      - alert: NODE_LOAD_HIGH
        expr: node:ins:stdload5 > 1
        for: 3m
        labels:
          severity: P2
        annotations:
          summary: "P2 Node Load High: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:ins:stdload5[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 100%
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=37&fullscreen&var-ip={{ $labels.ip }}



      #==============================================================#
      #                      Disk & Filesystem                       #
      #==============================================================#
      # main fs readonly triggers an immediate P0 alert
      - alert: NODE_FS_READONLY
        expr: node_filesystem_readonly{fstype!~"(n|root|tmp)fs.*"} == 1
        labels:
          severity: P0
        annotations:
          summary: "P0 Node Filesystem Readonly: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node_filesystem_readonly{ins={{ $labels.ins }}, ip={{ $labels.ip }},fstype!~"(n|root|tmp)fs.*"} == 1
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=110&fullscreen&var-ip={{ $labels.ip }}

      # main fs usage > 90% for 1m triggers P1 alert
      - alert: NODE_FS_SPACE_FULL
        expr: node:fs:space_usage > 0.90
        for: 1m
        labels:
          severity: P1
        annotations:
          summary: "P1 Node Filesystem Space Full: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:fs:space_usage[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 90%
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=110&fullscreen&var-ip={{ $labels.ip }}

      # main fs inode usage > 90% for 1m triggers P1 alert
      - alert: NODE_FS_INODE_FULL
        expr: node:fs:inode_usage > 0.90
        for: 1m
        labels:
          severity: P1
        annotations:
          summary: "P1 Node Filesystem iNode Full: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:fs:inode_usage[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 90%
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=110&fullscreen&var-ip={{ $labels.ip }}

      # fd usage > 90% for 1m triggers P1 alert
      - alert: NODE_FD_FULL
        expr: node:fs:fd_usage > 0.90
        for: 1m
        labels:
          severity: P1
        annotations:
          summary: "P1 Node File Descriptor Full: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:fs:fd_usage[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 90%
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=58&fullscreen&var-ip={{ $labels.ip }}


      # ssd read latency > 32ms for 3m (except long-read)
      - alert: NODE_READ_LATENCY_HIGH
        expr: node:dev:disk_read_rt  < 10000 and node:dev:disk_read_rt  > 0.032
        for: 3m
        labels:
          severity: P2
        annotations:
          summary: "P2 Node Read Latency High: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:dev:disk_read_rt[ins={{ $labels.ins }}, ip={{ $labels.ip }}, device={{ $labels.device }}] = {{ $value }} > 32ms
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=29&fullscreen&var-ip={{ $labels.ip }}

      # ssd write latency > 16ms for 3m
      - alert: NODE_WRITE_LATENCY_HIGH
        expr: node:dev:disk_write_rt  < 10000 and node:dev:disk_write_rt  > 0.016
        for: 3m
        labels:
          severity: P2
        annotations:
          summary: "P2 Node Write Latency High: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:dev:disk_write_rt[ins={{ $labels.ins }}, ip={{ $labels.ip }}, device={{ $labels.device }}] = {{ $value }} > 16ms
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=29&fullscreen&var-ip={{ $labels.ip }}



      #==============================================================#
      #                           Memory                             #
      #==============================================================#
      # shared memory usage > 80% for 1m triggers a P1 alert
      - alert: NODE_MEM_HIGH
        expr: node:ins:mem_usage > 0.80
        for: 1m
        labels:
          severity: P1
        annotations:
          summary: "P1 Node Mem High: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:ins:mem_usage[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 80%
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=40&fullscreen&var-ip={{ $labels.ip }}



      #==============================================================#
      #                      Network & TCP                           #
      #==============================================================#
      # node tcp listen overflow > 2 for 3m
      - alert: NODE_TCP_LISTEN_OVERFLOW
        expr: node:ins:tcp_overflow_rate > 2
        for: 3m
        labels:
          severity: P1
        annotations:
          summary: "P1 Node TCP Listen Overflow: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:ins:tcp_overflow_rate[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 2
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=55&fullscreen&var-ip={{ $labels.ip }}

      # node tcp retrans > 32 per sec for 3m
      - alert: NODE_TCP_RETRANS_HIGH
        expr: node:ins:tcp_retranssegs > 32
        for: 3m
        labels:
          severity: P2
        annotations:
          summary: "P2 Node TCP Retrans High: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node:ins:tcp_retranssegs[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 32
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=52&fullscreen&var-ip={{ $labels.ip }}

      # node tcp conn > 32768 for 1m
      - alert: NODE_TCP_CONN_HIGH
        expr: node_netstat_Tcp_CurrEstab > 32768
        for: 3m
        labels:
          severity: P2
        annotations:
          summary: "P2 Node TCP Connection High: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node_netstat_Tcp_CurrEstab[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 32768
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=54&fullscreen&var-ip={{ $labels.ip }}



      #==============================================================#
      #                          Misc                                #
      #==============================================================#
      # node ntp offset > 1s for 1m
      - alert: NODE_NTP_OFFSET_HIGH
        expr: abs(node_ntp_offset_seconds) > 1
        for: 1m
        labels:
          severity: P1
        annotations:
          summary: "P1 Node NTP Offset High: {{ $labels.ins }} {{ $labels.ip }}"
          description: |
            node_ntp_offset_seconds[ins={{ $labels.ins }}, ip={{ $labels.ip }}] = {{ $value }} > 32768
            http://g.pigsty/d/node?&from=now-10m&to=now&viewPanel=70&fullscreen&var-ip={{ $labels.ip }}






...